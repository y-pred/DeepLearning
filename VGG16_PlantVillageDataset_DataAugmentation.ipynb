{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jPVj7BL1z6fH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.applications.vgg16 import VGG16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "4GqIcfPP0CE4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d emmarex/plantdisease"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4r1zsi70DdH",
        "outputId": "8fe3a078-48fa-49fa-f9eb-ec09936d2f9c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading plantdisease.zip to /content\n",
            " 99% 653M/658M [00:06<00:00, 162MB/s]\n",
            "100% 658M/658M [00:06<00:00, 101MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/plantdisease.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "fkEORXko0EwV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define constants\n",
        "IMAGE_SIZE = (150, 150)\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "id": "0_2dMj9Q0JTo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "dataset_path = '/content/PlantVillage'\n",
        "\n",
        "# Get the list of subdirectories (classes) in the dataset\n",
        "classes = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
        "\n",
        "# Print the class names\n",
        "for class_name in classes:\n",
        "    print(class_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lOnhUdE0LMr",
        "outputId": "58fcb530-b397-4395-ffbb-a816beb710c5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tomato_Leaf_Mold\n",
            "Tomato_Early_blight\n",
            "Pepper__bell___healthy\n",
            "Tomato__Tomato_YellowLeaf__Curl_Virus\n",
            "Potato___healthy\n",
            "Tomato_Bacterial_spot\n",
            "Pepper__bell___Bacterial_spot\n",
            "Tomato__Target_Spot\n",
            "Potato___Late_blight\n",
            "Potato___Early_blight\n",
            "Tomato__Tomato_mosaic_virus\n",
            "Tomato_Septoria_leaf_spot\n",
            "Tomato_Spider_mites_Two_spotted_spider_mite\n",
            "Tomato_healthy\n",
            "Tomato_Late_blight\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation"
      ],
      "metadata": {
        "id": "49ZdnIsc0PFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load PlantVillage dataset using ImageDataGenerator\n",
        "#train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        validation_split=0.2)"
      ],
      "metadata": {
        "id": "-UX9NUQ80NFS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/PlantVillage',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',  # since we  have multiple classes\n",
        "    subset='training'\n",
        "    #classes=target_folders\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    '/content/PlantVillage',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        "    #classes=target_folders\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWNz5Qar0Tmy",
        "outputId": "f60e9d50-b230-40e9-8550-6718b576941f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 16516 images belonging to 15 classes.\n",
            "Found 4122 images belonging to 15 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base = VGG16(\n",
        "    weights = 'imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(150,150,3)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x_K9bqh0YYC",
        "outputId": "28d736d8-9b9c-4b3c-8a7a-7f6acd3981f0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(conv_base)\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(Dense(len(train_generator.class_indices),activation='softmax'))"
      ],
      "metadata": {
        "id": "kNoRBRn_0Z9R"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "GN0PwHNZ0cLi"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=5,\n",
        "                    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T3uwk-J0ein",
        "outputId": "a3a08f46-355d-4cba-8197-02bf34122636"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "517/517 [==============================] - 201s 348ms/step - loss: 2.0716 - accuracy: 0.3260 - val_loss: 1.6880 - val_accuracy: 0.4505\n",
            "Epoch 2/5\n",
            "517/517 [==============================] - 162s 313ms/step - loss: 1.2965 - accuracy: 0.5652 - val_loss: 1.0598 - val_accuracy: 0.6361\n",
            "Epoch 3/5\n",
            "517/517 [==============================] - 162s 313ms/step - loss: 0.9638 - accuracy: 0.6726 - val_loss: 0.8020 - val_accuracy: 0.7251\n",
            "Epoch 4/5\n",
            "517/517 [==============================] - 161s 311ms/step - loss: 0.7709 - accuracy: 0.7397 - val_loss: 0.7211 - val_accuracy: 0.7475\n",
            "Epoch 5/5\n",
            "517/517 [==============================] - 177s 342ms/step - loss: 0.6231 - accuracy: 0.7871 - val_loss: 0.6228 - val_accuracy: 0.7872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions"
      ],
      "metadata": {
        "id": "FT6cPeK50noN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess an individual image\n",
        "def preprocess_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(150, 150))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    return img_array\n",
        "\n",
        "# Function to make predictions on an individual image\n",
        "def predict_image(img_path):\n",
        "    processed_img = preprocess_image(img_path)\n",
        "    predictions = model.predict(processed_img)\n",
        "    print(classes[np.argmax(predictions)])\n",
        "    print(np.argmax(predictions))\n",
        "   # decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
        "    #return decoded_predictions\n",
        "\n",
        "# Test the model on an example image\n",
        "img_path = '/content/Pepper__bell___Bacterial_spot.jpg'\n",
        "predictions = predict_image(img_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTflVoPW0oDQ",
        "outputId": "fae913df-bed1-4f5b-f9a3-d6c23965cc33"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "Potato___Early_blight\n",
            "9\n"
          ]
        }
      ]
    }
  ]
}