{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75cFOh5kGAGe"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Flatten\n",
        "from keras.applications.vgg16 import VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UIMVTnjvHeEj"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_E2g0oGBHrl4",
        "outputId": "e27d721f-0098-4b55-ee26-83a3fe8009ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "plantdisease.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d emmarex/plantdisease"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rar04YEyHxBy"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile('/content/plantdisease.zip', 'r')\n",
        "zip_ref.extractall('/content')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3m3pLiSLLgY"
      },
      "outputs": [],
      "source": [
        "# Define constants\n",
        "IMAGE_SIZE = (150, 150)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Specify target labels\n",
        "target_folders = ['Pepper__bell___Bacterial_spot', 'Pepper__bell___healthy', 'Potato___Early_blight', 'Potato___Late_blight', 'Potato___healthy']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDp49RfJ9drw",
        "outputId": "d2bdd806-1022-4695-b09c-77ccb35dfd0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tomato_Leaf_Mold\n",
            "Pepper__bell___healthy\n",
            "Potato___Early_blight\n",
            "Tomato_Spider_mites_Two_spotted_spider_mite\n",
            "Tomato_healthy\n",
            "Potato___healthy\n",
            "Tomato__Target_Spot\n",
            "Tomato_Septoria_leaf_spot\n",
            "Pepper__bell___Bacterial_spot\n",
            "Tomato__Tomato_mosaic_virus\n",
            "Tomato__Tomato_YellowLeaf__Curl_Virus\n",
            "Tomato_Late_blight\n",
            "Tomato_Early_blight\n",
            "Tomato_Bacterial_spot\n",
            "Potato___Late_blight\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "dataset_path = '/content/PlantVillage'\n",
        "\n",
        "# Get the list of subdirectories (classes) in the dataset\n",
        "classes = [d for d in os.listdir(dataset_path) if os.path.isdir(os.path.join(dataset_path, d))]\n",
        "\n",
        "# Print the class names\n",
        "for class_name in classes:\n",
        "    print(class_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMd6wAQaLQmv"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Load PlantVillage dataset using ImageDataGenerator\n",
        "#train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        validation_split=0.2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnxLzvfDLZgX",
        "outputId": "6d631004-471e-4004-e8e6-09564cece95c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3703 images belonging to 5 classes.\n",
            "Found 924 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/PlantVillage',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',  # since we  have multiple classes\n",
        "    subset='training',\n",
        "    classes=target_folders\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    '/content/PlantVillage',\n",
        "    target_size=IMAGE_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        "    classes=target_folders\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97egc1JXIBGp"
      },
      "outputs": [],
      "source": [
        "conv_base = VGG16(\n",
        "    weights = 'imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(150,150,3)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQVADem_IQ-Y"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(conv_base)\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256,activation='relu'))\n",
        "model.add(Dense(len(train_generator.class_indices),activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddv1YnsALxHn"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "a8jFzc-SL7NH"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=5,\n",
        "                    validation_data=validation_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgEHtvho0XzD"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t82So36v0Y8p"
      },
      "outputs": [],
      "source": [
        "# Function to preprocess an individual image\n",
        "def preprocess_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(150, 150))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    return img_array\n",
        "\n",
        "# Function to make predictions on an individual image\n",
        "def predict_image(img_path):\n",
        "    processed_img = preprocess_image(img_path)\n",
        "    predictions = model.predict(processed_img)\n",
        "    print(target_folders[np.argmax(predictions)])\n",
        "    print(np.argmax(predictions))\n",
        "   # decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
        "    #return decoded_predictions\n",
        "\n",
        "# Test the model on an example image\n",
        "img_path = '/content/Pepper__bell___healthy.jpg'\n",
        "predictions = predict_image(img_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qASQYlVi3J1L"
      },
      "outputs": [],
      "source": [
        "# Function to preprocess an individual image\n",
        "def preprocess_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(150, 150))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    return img_array\n",
        "\n",
        "# Function to make predictions on an individual image\n",
        "def predict_image(img_path):\n",
        "    processed_img = preprocess_image(img_path)\n",
        "    predictions = model.predict(processed_img)\n",
        "    print(np.argmax(predictions))\n",
        "    print(classes[np.argmax(predictions)])\n",
        "   # decoded_predictions = decode_predictions(predictions, top=3)[0]\n",
        "    #return decoded_predictions\n",
        "\n",
        "# Test the model on an example image\n",
        "img_path = '/content/Pepper__bell___healthy.jpg'\n",
        "predictions = predict_image(img_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n83sZbH13Hxj"
      },
      "outputs": [],
      "source": [
        "# Display the predictions\n",
        "for i, (imagenet_id, label, score) in enumerate(predictions):\n",
        "    print(f\"{i + 1}: {label} ({score:.2f})\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}